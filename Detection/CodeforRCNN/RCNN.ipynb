{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"HlSy6nZ-8hJC"},"outputs":[],"source":["!unzip images.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8odLCHX98rLz"},"outputs":[],"source":["!unzip annot.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j5VNMuVS8wgr"},"outputs":[],"source":["import os,cv2,keras\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LslzdDoA81N6"},"outputs":[],"source":["path = \"images\"\n","annot = \"annot\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Th48INo0854_"},"outputs":[],"source":["cv2.setUseOptimized(True);\n","ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"foRE6-nf88bf"},"outputs":[],"source":["train_images=[]\n","train_labels=[]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cV_K7phN89qj"},"outputs":[],"source":["def get_iou(bb1, bb2):\n","    assert bb1['x1'] < bb1['x2']\n","    assert bb1['y1'] < bb1['y2']\n","    assert bb2['x1'] < bb2['x2']\n","    assert bb2['y1'] < bb2['y2']\n","\n","    x_left = max(bb1['x1'], bb2['x1'])\n","    y_top = max(bb1['y1'], bb2['y1'])\n","    x_right = min(bb1['x2'], bb2['x2'])\n","    y_bottom = min(bb1['y2'], bb2['y2'])\n","\n","    if x_right < x_left or y_bottom < y_top:\n","        return 0.0\n","\n","    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n","\n","    bb1_area = (bb1['x2'] - bb1['x1']) * (bb1['y2'] - bb1['y1'])\n","    bb2_area = (bb2['x2'] - bb2['x1']) * (bb2['y2'] - bb2['y1'])\n","\n","    iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n","    assert iou >= 0.0\n","    assert iou <= 1.0\n","    return iou"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DfqsDOeY8-uv"},"outputs":[],"source":["ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jNNkB0_78_sh"},"outputs":[],"source":["for e,i in enumerate(os.listdir(annot)):\n","    try:\n","            filename = i.split(\".\")[0]+\".jpg\"\n","            print(e,filename)\n","            image = cv2.imread(os.path.join(path,filename))\n","            df = pd.read_csv(os.path.join(annot,i))\n","            gtvalues=[]\n","            for row in df.iterrows():\n","                x1 = int(row[1][0].split(\" \")[0])\n","                y1 = int(row[1][0].split(\" \")[1])\n","                x2 = int(row[1][0].split(\" \")[2])\n","                y2 = int(row[1][0].split(\" \")[3])\n","                gtvalues.append({\"x1\":x1,\"x2\":x2,\"y1\":y1,\"y2\":y2})\n","            ss.setBaseImage(image)\n","            ss.switchToSelectiveSearchFast()\n","            ssresults = ss.process()\n","            imout = image.copy()\n","            counter = 0\n","            falsecounter = 0\n","            flag = 0\n","            fflag = 0\n","            bflag = 0\n","            for e,result in enumerate(ssresults):\n","                if e < 2000 and flag == 0:\n","                    for gtval in gtvalues:\n","                        x,y,w,h = result\n","                        iou = get_iou(gtval,{\"x1\":x,\"x2\":x+w,\"y1\":y,\"y2\":y+h})\n","                        if counter < 30:\n","                            if iou > 0.70:\n","                                timage = imout[y:y+h,x:x+w]\n","                                resized = cv2.resize(timage, (224,224), interpolation = cv2.INTER_AREA)\n","                                train_images.append(resized)\n","                                train_labels.append(1)\n","                                counter += 1\n","                        else :\n","                            fflag =1\n","                        if falsecounter <30:\n","                            if iou < 0.3:\n","                                timage = imout[y:y+h,x:x+w]\n","                                resized = cv2.resize(timage, (224,224), interpolation = cv2.INTER_AREA)\n","                                train_images.append(resized)\n","                                train_labels.append(0)\n","                                falsecounter += 1\n","                        else :\n","                            bflag = 1\n","                    if fflag == 1 and bflag == 1:\n","                        print(\"inside\")\n","                        flag = 1\n","    except Exception as e:\n","        print(e)\n","        continue"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oO8jmv4b9BEZ"},"outputs":[],"source":["X_new = np.array(train_images)\n","y_new = np.array(train_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HINk0OOl9CKf"},"outputs":[],"source":["X_new.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-7dj8qUo9DyI"},"outputs":[],"source":["from keras.layers import Dense\n","from keras import Model\n","from keras import optimizers\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.applications.vgg16 import VGG16"]},{"cell_type":"markdown","metadata":{"id":"hRcWpQT4BFMW"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6IwSkc_19Fbi"},"outputs":[],"source":["vggmodel = VGG16(weights='imagenet', include_top=True)\n","vggmodel.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s2psDF739GWJ"},"outputs":[],"source":["for layers in (vggmodel.layers)[:15]:\n","    print(layers)\n","    layers.trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cmhPHj8Q9Gr2"},"outputs":[],"source":["X= vggmodel.layers[-2].output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2oUPNAJN9HtY"},"outputs":[],"source":["predictions = Dense(2, activation=\"softmax\")(X)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jMduxeRE9IjP"},"outputs":[],"source":["model_final = Model(vggmodel.input, predictions)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JS0BBra09Jbv"},"outputs":[],"source":["from tensorflow.keras.optimizers import Adam\n","opt = Adam(lr=0.0001)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rRQ-jYGv9KOA"},"outputs":[],"source":["model_final.compile(loss = keras.losses.categorical_crossentropy, optimizer = opt, metrics=[\"accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"it6OPbco9L83"},"outputs":[],"source":["model_final.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ARhIpr559NBf"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelBinarizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HZrRiB439N1B"},"outputs":[],"source":["class MyLabelBinarizer(LabelBinarizer):\n","    def transform(self, y):\n","        Y = super().transform(y)\n","        if self.y_type_ == 'binary':\n","            return np.hstack((Y, 1-Y))\n","        else:\n","            return Y\n","    def inverse_transform(self, Y, threshold=None):\n","        if self.y_type_ == 'binary':\n","            return super().inverse_transform(Y[:, 0], threshold)\n","        else:\n","            return super().inverse_transform(Y, threshold)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y6IhSRbk9OtH"},"outputs":[],"source":["lenc = MyLabelBinarizer()\n","Y =  lenc.fit_transform(y_new)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h6hMlxKq9Pjo"},"outputs":[],"source":["X_train, X_test , y_train, y_test = train_test_split(X_new,Y,test_size=0.10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ytOKPbh99Qbw"},"outputs":[],"source":["print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5_8Whgr59Rgf"},"outputs":[],"source":["trdata = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rotation_range=90)\n","traindata = trdata.flow(x=X_train, y=y_train)\n","tsdata = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rotation_range=90)\n","testdata = tsdata.flow(x=X_test, y=y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y_Tm4RVB9SWx"},"outputs":[],"source":["from keras.callbacks import ModelCheckpoint, EarlyStopping"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LjhSZx139Th_"},"outputs":[],"source":["checkpoint = ModelCheckpoint(\"ieeercnn_vgg16_1.h5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n","early = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, mode='auto')\n","hist = model_final.fit_generator(generator= traindata, steps_per_epoch= 10, epochs= 30, validation_data= testdata, validation_steps=2, callbacks=[checkpoint,early])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4cVVXxJD9Vln"},"outputs":[],"source":["im = X_test[585]\n","plt.imshow(im)\n","img = np.expand_dims(im, axis=0)\n","out = model_final.predict(img)\n","if out[0][0] > out[0][1]:\n","    print(\"character\")\n","else:\n","    print(\"not character\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DRrWPHNMU4WK"},"outputs":[],"source":["path1 = \"test_black_nonoisedata\"\n","path2 = \"test_black_n_noisedata\"\n","path3 = \"test_color_nonoisedata\"\n","path4 = \"test_color_n_nonoisedata\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VDzqk4fiManp"},"outputs":[],"source":["!unzip test_black_nonoisedata.zip\n","!unzip test_black_n_noisedata.zip\n","!unzip test_color_nonoisedata.zip\n","!unzip test_color_n_nonoisedata.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wz60AsuV9Ws3"},"outputs":[],"source":["z=0\n","for e,i in enumerate(os.listdir(path1)):\n","        z += 1\n","        img = cv2.imread(os.path.join(path1,i))\n","        ss.setBaseImage(img)\n","        ss.switchToSelectiveSearchFast()\n","        ssresults = ss.process()\n","        imout = img.copy()\n","        for e,result in enumerate(ssresults):\n","            if e < 2000:\n","                x,y,w,h = result\n","                timage = imout[y:y+h,x:x+w]\n","                resized = cv2.resize(timage, (224,224), interpolation = cv2.INTER_AREA)\n","                img = np.expand_dims(resized, axis=0)\n","                t = time.time()\n","                out= model_final.predict(img)\n","                \n","                if out[0][0] > 0.65:\n","                    cv2.rectangle(imout, (x, y), (x+w, y+h), (0, 255, 0), 1, cv2.LINE_AA)\n","        plt.figure()\n","        plt.imshow(imout)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6urWtLW_QNpa"},"outputs":[],"source":["import cv2\n","import numpy as np\n","import glob\n","import random\n","import time\n","time_check = 0\n","\n","# Load Yolo\n","net = cv2.dnn.readNet(\"yolov3_training_last.weights\", \"yolov3_testing.cfg\")\n","\n","# Name custom object\n","classes = [\"character\"]\n","\n","# Images path\n","images_path = glob.glob(r\"test_color_n_nonoisedata/*.jpg\")\n","\n","\n","\n","layer_names = net.getLayerNames()\n","output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n","colors = np.random.uniform(0, 255, size=(len(classes), 3))\n","\n","# Insert here the path of your images\n","random.shuffle(images_path)\n","# loop through all the images\n","for img_path in images_path:\n","    # Loading image\n","    img = cv2.imread(img_path)\n","    img = cv2.resize(img, None, fx=0.4, fy=0.4)\n","    height, width, channels = img.shape\n","\n","    # Detecting objects\n","    T_check = time.time()\n","    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n","    time_check += time.time() - T_check\n","\n","    net.setInput(blob)\n","    outs = net.forward(output_layers)\n","\n","    # Showing informations on the screen\n","    class_ids = []\n","    confidences = []\n","    boxes = []\n","    for out in outs:\n","        for detection in out:\n","            scores = detection[5:]\n","            class_id = np.argmax(scores)\n","            confidence = scores[class_id]\n","            if confidence > 0.3:\n","                # Object detected\n","                # print(class_id)\n","                center_x = int(detection[0] * width)\n","                center_y = int(detection[1] * height)\n","                w = int(detection[2] * width)\n","                h = int(detection[3] * height)\n","\n","                # Rectangle coordinates\n","                x = int(center_x - w / 2)\n","                y = int(center_y - h / 2)\n","\n","                boxes.append([x, y, w, h])\n","                confidences.append(float(confidence))\n","                class_ids.append(class_id)\n","    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n","    thresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,51,9)\n","    \n","    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n","    # print(indexes)\n","    font = cv2.FONT_HERSHEY_PLAIN\n","    for i in range(len(boxes)):\n","        if i in indexes:\n","            x, y, w, h = boxes[i]\n","            x -= 10\n","            y -= 10\n","            w += 20\n","            h += 20\n","            label = str(classes[class_ids[i]])\n","            color = colors[class_ids[i]]\n","            cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n","\n","\n","\n","    # cv2.imshow(\"Image\", img)\n","    key = cv2.waitKey(0)\n","print(time_check)\n","cv2.destroyAllWindows()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO+VEvh+ELXF/UGozEQC6Ag","name":"RCNN.ipynb","private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
